{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"Time (s)\", \"X (m/s2)\", \"Y (m/s2)\", \"Z (m/s2)\", \"R (m/s2)\", \"Theta (deg)\", \"Phi (deg)\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        # Read all lines from the file, skipping the first four metadata lines\n",
    "        lines = file.readlines()[4:]\n",
    "        \n",
    "        # Initialize an empty list to hold parsed data\n",
    "        data = []\n",
    "        # count=0\n",
    "        # Process each line, split by comma, and strip any leading/trailing whitespace\n",
    "        for line in lines:\n",
    "            values = line.strip().split(',')\n",
    "            # print(values)\n",
    "            if len(values) == len(column_names):  # Ensure correct number of columns\n",
    "                data.append(values)\n",
    "            # if count<=5:\n",
    "            #     print(column_names)\n",
    "            #     print(data)\n",
    "            #     count+=1\n",
    "            \n",
    "        \n",
    "        # Create DataFrame with specified column names\n",
    "        df = pd.DataFrame(data, columns=column_names)\n",
    "        # print(df)\n",
    "        # Convert numeric columns to float where applicable\n",
    "        numeric_columns = column_names[1:]  # Exclude 'Time (s)'\n",
    "        print(numeric_columns)\n",
    "        df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'LA': 'Final_Dataset/Abhay/LA.csv',\n",
    "    'RA': 'Final_Dataset/Abhay/RA.csv',\n",
    "    'LK': 'Final_Dataset/Abhay/LK.csv',\n",
    "    'RK': 'Final_Dataset/Abhay/RK.csv',\n",
    "    'LH': 'Final_Dataset/Abhay/LH.csv',\n",
    "    'RH': 'Final_Dataset/Abhay/RH.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Final_Dataset/Abhay/LA.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2d/fcgrngd95_b823fdj1fwwj840000gn/T/ipykernel_9584/2987451719.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data for each body part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(data['LH'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2d/fcgrngd95_b823fdj1fwwj840000gn/T/ipykernel_9584/2987451719.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load data for each body part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(data['LH'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/2d/fcgrngd95_b823fdj1fwwj840000gn/T/ipykernel_9584/3354079100.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;31m# Read all lines from the file, skipping the first four metadata lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Final_Dataset/Abhay/LA.csv'"
     ]
    }
   ],
   "source": [
    "# Load data for each body part\n",
    "data = {key: load_data(file) for key, file in files.items()}\n",
    "# print(data['LH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['LA'].head())\n",
    "print(data['RA'].head())\n",
    "print(data['LH'].head())\n",
    "print(data['RH'].head())\n",
    "print(data['LK'].head())\n",
    "print(data['RK'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theta(data1, data2, label1, label2, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Theta (deg) for data1 and data2 (first 500 rows)\n",
    "    plt.plot(data1.index[:1000], data1['Theta (deg)'].iloc[:1000], label=f'{label1} Theta (deg)')\n",
    "    plt.plot(data2.index[:1000], data2['Theta (deg)'].iloc[:1000], label=f'{label2} Theta (deg)', linestyle='dashed')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Row index')\n",
    "    plt.ylabel('Theta (deg)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting LA and RA together\n",
    "plot_theta(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# Plotting LK and RK together\n",
    "plot_theta(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# Plotting LH and RH together\n",
    "plot_theta(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_X(data1, data2, label1, label2, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Theta (deg) for data1 and data2 (first 500 rows)\n",
    "    plt.plot(data1.index[:1000], data1['X (m/s2)'].iloc[:1000], label=f'{label1} X (m/s2)')\n",
    "    plt.plot(data2.index[:1000], data2['X (m/s2)'].iloc[:1000], label=f'{label2} X (m/s2)', linestyle='dashed')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Row index')\n",
    "    plt.ylabel('X (m/s2)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting LA and RA together\n",
    "plot_X(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# Plotting LK and RK together\n",
    "plot_X(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# Plotting LH and RH together\n",
    "plot_X(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Y(data1, data2, label1, label2, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Theta (deg) for data1 and data2 (first 500 rows)\n",
    "    plt.plot(data1.index[:1000], data1['Y (m/s2)'].iloc[:1000], label=f'{label1} Y (m/s2)')\n",
    "    plt.plot(data2.index[:1000], data2['Y (m/s2)'].iloc[:1000], label=f'{label2} Y (m/s2)', linestyle='dashed')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Row index')\n",
    "    plt.ylabel('Y (m/s2)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting LA and RA together\n",
    "plot_Y(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# Plotting LK and RK together\n",
    "plot_Y(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# Plotting LH and RH together\n",
    "plot_Y(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_Z(data1, data2, label1, label2, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Theta (deg) for data1 and data2 (first 500 rows)\n",
    "    plt.plot(data1.index[:1000], data1['Z (m/s2)'].iloc[:1000], label=f'{label1} Z (m/s2)')\n",
    "    plt.plot(data2.index[:1000], data2['Z (m/s2)'].iloc[:1000], label=f'{label2} Z (m/s2)', linestyle='dashed')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Row index')\n",
    "    plt.ylabel('Z (m/s2)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting LA and RA together\n",
    "plot_Z(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# Plotting LK and RK together\n",
    "plot_Z(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# Plotting LH and RH together\n",
    "plot_Z(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_R(data1, data2, label1, label2, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Theta (deg) for data1 and data2 (first 500 rows)\n",
    "    plt.plot(data1.index[:1000], data1['R (m/s2)'].iloc[:1000], label=f'{label1} R (m/s2)')\n",
    "    plt.plot(data2.index[:1000], data2['R (m/s2)'].iloc[:1000], label=f'{label2} R (m/s2)', linestyle='dashed')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Row index')\n",
    "    plt.ylabel('R (m/s2)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting LA and RA together\n",
    "plot_R(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# Plotting LK and RK together\n",
    "plot_R(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# Plotting LH and RH together\n",
    "plot_R(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_phi(data1, data2, label1, label2, title):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot Theta (deg) for data1 and data2 (first 500 rows)\n",
    "    plt.plot(data1.index[:1000], data1['Phi (deg)'].iloc[:1000], label=f'{label1} Phi (deg)')\n",
    "    plt.plot(data2.index[:1000], data2['Phi (deg)'].iloc[:1000], label=f'{label2} Phi (deg)', linestyle='dashed')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Row index')\n",
    "    plt.ylabel('Phi (deg)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Plotting LA and RA together\n",
    "plot_phi(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# Plotting LK and RK together\n",
    "plot_phi(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# Plotting LH and RH together\n",
    "plot_phi(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_theta_side(data1, data2, label1, label2, title):\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), sharey=True)\n",
    "    \n",
    "#     # Plot for data1\n",
    "#     ax1.plot(data1.index[:1000], data1['Theta (deg)'].iloc[:1000], label=f'{label1} Theta (deg)')\n",
    "#     ax1.set_title(f'{label1} - {title}')\n",
    "#     ax1.set_xlabel('Row index')\n",
    "#     ax1.set_ylabel('X (m/s2)')\n",
    "#     ax1.legend()\n",
    "    \n",
    "#     # Plot for data2\n",
    "#     ax2.plot(data2.index[:1000], data2['Theta (deg)'].iloc[:1000], label=f'{label2} Theta (deg)', linestyle='dashed')\n",
    "#     ax2.set_title(f'{label2} - {title}')\n",
    "#     ax2.set_xlabel('Row index')\n",
    "#     ax2.legend()\n",
    "    \n",
    "#     plt.suptitle(title)\n",
    "#     plt.show()\n",
    "    \n",
    "# # Plotting LA and RA together\n",
    "# plot_theta_side(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# # Plotting LK and RK together\n",
    "# plot_theta_side(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# # Plotting LH and RH together\n",
    "# plot_theta_side(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_X_side(data1, data2, label1, label2, title):\n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6), sharey=True)\n",
    "    \n",
    "#     # Plot for data1\n",
    "#     ax1.plot(data1.index[:1000], data1['X (m/s2)'].iloc[:1000], label=f'{label1} X (m/s2)')\n",
    "#     ax1.set_title(f'{label1} - {title}')\n",
    "#     ax1.set_xlabel('Row index')\n",
    "#     ax1.set_ylabel('X (m/s2)')\n",
    "#     ax1.legend()\n",
    "    \n",
    "#     # Plot for data2\n",
    "#     ax2.plot(data2.index[:1000], data2['X (m/s2)'].iloc[:1000], label=f'{label2} X (m/s2)', linestyle='dashed')\n",
    "#     ax2.set_title(f'{label2} - {title}')\n",
    "#     ax2.set_xlabel('Row index')\n",
    "#     ax2.legend()\n",
    "    \n",
    "#     plt.suptitle(title)\n",
    "#     plt.show()\n",
    "    \n",
    "# # Plotting LA and RA together\n",
    "# plot_X_side(data['LA'], data['RA'], 'LA', 'RA', 'Left Ankle (LA) and Right Ankle (RA)')\n",
    "\n",
    "# # Plotting LK and RK together\n",
    "# plot_X_side(data['LK'], data['RK'], 'LK', 'RK', 'Left Knee (LK) and Right Knee (RK)')\n",
    "\n",
    "# # Plotting LH and RH together\n",
    "# plot_X_side(data['LH'], data['RH'], 'LH', 'RH', 'Left Hip (LH) and Right Hip (RH)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, medfilt, savgol_filter\n",
    "from scipy.ndimage import gaussian_filter as scipy_gaussian_filter\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function Definitions\n",
    "\n",
    "# def moving_average(data, window_size):\n",
    "#     return data.rolling(window=window_size).mean()\n",
    "\n",
    "# def low_pass_filter(data, cutoff_frequency, sample_rate):\n",
    "#     nyquist = 0.5 * sample_rate\n",
    "#     normal_cutoff = cutoff_frequency / nyquist\n",
    "#     b, a = butter(1, normal_cutoff, btype='low', analog=False)\n",
    "#     return filtfilt(b, a, data)\n",
    "\n",
    "def median_filter(data, kernel_size):\n",
    "    return medfilt(data, kernel_size)\n",
    "\n",
    "def gaussian_filter_custom(data, sigma):\n",
    "    return scipy_gaussian_filter(data, sigma=sigma)\n",
    "\n",
    "# def savitzky_golay_filter(data, window_size, poly_order):\n",
    "#     return savgol_filter(data, window_length=window_size, polyorder=poly_order)\n",
    "\n",
    "# def wavelet_denoising(data, wavelet, level):\n",
    "#     coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "#     threshold = np.sqrt(2 * np.log(len(data)))\n",
    "#     coeffs[1:] = [pywt.threshold(i, value=threshold, mode='soft') for i in coeffs[1:]]\n",
    "#     return pywt.waverec(coeffs, wavelet)\n",
    "# def wavelet_denoising(data, wavelet='db1', level=1):\n",
    "#     coeffs = pywt.wavedec(data, wavelet, level=level)\n",
    "#     threshold = np.sqrt(2 * np.log(len(data))) * np.median(np.abs(coeffs[-level])) / 0.6745\n",
    "#     new_coeffs = [pywt.threshold(i, value=threshold, mode='soft') for i in coeffs]\n",
    "#     return pywt.waverec(new_coeffs, wavelet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the columns are numeric\n",
    "new_data = data['RK'].copy()\n",
    "columns_to_process = ['X (m/s2)', 'Y (m/s2)', 'Z (m/s2)', 'R (m/s2)', 'Theta (deg)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate Mean Absolute Error (MAE)\n",
    "def mean_absolute_error(original, filtered):\n",
    "    return np.mean(np.abs(original - filtered))\n",
    "\n",
    "# Function to calculate Mean Squared Error (MSE)\n",
    "def mean_squared_error(original, filtered):\n",
    "    return np.mean((original - filtered) ** 2)\n",
    "data_loss = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_process:\n",
    "    new_data[column] = pd.to_numeric(new_data[column], errors='coerce')\n",
    "    new_data[column].fillna(method='ffill', inplace=True)  # Forward fill for simplicity\n",
    "\n",
    "    # Apply noise removal methods\n",
    "    # new_data[f'{column}_moving_avg'] = moving_average(new_data[column], window_size=5)\n",
    "    # new_data[f'{column}_low_pass'] = low_pass_filter(new_data[column], cutoff_frequency=0.1, sample_rate=100)\n",
    "    # new_data[f'{column}_median'] = median_filter(new_data[column], kernel_size=5)\n",
    "    # new_data[f'{column}_gaussian'] = gaussian_filter_custom(new_data[column], sigma=1)\n",
    "    # new_data[f'{column}_savgol'] = savitzky_golay_filter(new_data[column], window_size=11, poly_order=3)\n",
    "    # new_data[f'{column}_wavelet'] = wavelet_denoising(new_data[column], wavelet='db1', level=1)\n",
    "    \n",
    "     # Apply median filter\n",
    "    new_data[f'{column}_median'] = median_filter(new_data[column], kernel_size=5)\n",
    "    \n",
    "    # Apply Gaussian filter on the result of the median filter\n",
    "    new_data[f'{column}_median_gaussian'] = gaussian_filter_custom(new_data[f'{column}_median'], sigma=1)\n",
    "    \n",
    "    \n",
    "    # Calculate data loss\n",
    "    data_loss[column] = {\n",
    "        'Median + Gaussian MAE': mean_absolute_error(new_data[column], new_data[f'{column}_median_gaussian']),\n",
    "        'Median + Gaussian MSE': mean_squared_error(new_data[column], new_data[f'{column}_median_gaussian']),\n",
    "        \n",
    "        \n",
    "        # 'Moving Avg MAE': mean_absolute_error(new_data[column], new_data[f'{column}_moving_avg']),\n",
    "        # 'Moving Avg MSE': mean_squared_error(new_data[column], new_data[f'{column}_moving_avg']),\n",
    "        # 'Low-pass Filter MAE': mean_absolute_error(new_data[column], new_data[f'{column}_low_pass']),\n",
    "        # 'Low-pass Filter MSE': mean_squared_error(new_data[column], new_data[f'{column}_low_pass']),\n",
    "        # 'Median Filter MAE': mean_absolute_error(new_data[column], new_data[f'{column}_median']),\n",
    "        # 'Median Filter MSE': mean_squared_error(new_data[column], new_data[f'{column}_median']),\n",
    "        # 'Gaussian Filter MAE': mean_absolute_error(new_data[column], new_data[f'{column}_gaussian']),\n",
    "        # 'Gaussian Filter MSE': mean_squared_error(new_data[column], new_data[f'{column}_gaussian']),\n",
    "        # 'Savgol Filter MAE': mean_absolute_error(new_data[column], new_data[f'{column}_savgol']),\n",
    "        # 'Savgol Filter MSE': mean_squared_error(new_data[column], new_data[f'{column}_savgol']),\n",
    "        # 'Wavelet Denoising MAE': mean_absolute_error(new_data[column], new_data[f'{column}_wavelet']),\n",
    "        # 'Wavelet Denoising MSE': mean_squared_error(new_data[column], new_data[f'{column}_wavelet']),\n",
    "    }\n",
    "    # Plot results\n",
    "    def plot_comparison(data, column):\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        fig.suptitle(f'Noise Removal Methods Comparison for {column}', fontsize=16)\n",
    "        \n",
    "        # Original\n",
    "        axs[0].plot(data.index[:1000], data[column][:1000], label='Original')\n",
    "        axs[0].set_title('Original')\n",
    "        axs[0].set_xlabel('Row index')\n",
    "        axs[0].set_ylabel(column)\n",
    "\n",
    "        # Median Filter\n",
    "        axs[1].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "        axs[1].plot(data.index[:1000], data[f'{column}_median'][:1000], label='Median Filtered', color='red')\n",
    "        axs[1].set_title('Median Filter')\n",
    "        axs[1].set_xlabel('Row index')\n",
    "\n",
    "        # Median + Gaussian Filter\n",
    "        axs[2].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "        axs[2].plot(data.index[:1000], data[f'{column}_median_gaussian'][:1000], label='Median + Gaussian Filtered', color='red')\n",
    "        axs[2].set_title('Median + Gaussian Filter')\n",
    "        axs[2].set_xlabel('Row index')\n",
    "\n",
    "        for ax in axs:\n",
    "            ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_comparison(new_data, column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "# def plot_comparison(data, label, column):\n",
    "    # fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    # fig.suptitle(f'Noise Removal Methods Comparison for {label}', fontsize=16)\n",
    "    \n",
    "    # Original\n",
    "    # axs[0].plot(data.index[:1000], data[column][:1000], label='Original')\n",
    "    # axs[0].set_title('Original')\n",
    "    # axs[0].set_xlabel('Row index')\n",
    "    # axs[0].set_ylabel(label)\n",
    "\n",
    "    # # Moving Average\n",
    "    # axs[1].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "    # axs[1].plot(data.index[:1000], data[f'{column}_moving_avg'][:1000], label='Filtered', color='red')\n",
    "    # axs[1].set_title('Moving Average')\n",
    "    # axs[1].set_xlabel('Row index')\n",
    "\n",
    "    # # Low-pass Filter\n",
    "    # axs[2].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "    # axs[2].plot(data.index[:1000], data[f'{column}_low_pass'][:1000], label='Filtered', color='red')\n",
    "    # axs[2].set_title('Low-pass Filter')\n",
    "    # axs[2].set_xlabel('Row index')\n",
    "\n",
    "    # Median Filter\n",
    "    # axs[1].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "    # axs[1].plot(data.index[:1000], data[f'{column}_median'][:1000], label='Filtered', color='red')\n",
    "    # axs[1].set_title('Median Filter')\n",
    "    # axs[1].set_xlabel('Row index')\n",
    "\n",
    "    # Gaussian Filter\n",
    "    # axs[2].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "    # axs[2].plot(data.index[:1000], data[f'{column}_gaussian'][:1000], label='Filtered', color='red')\n",
    "    # axs[2].set_title('Gaussian Filter')\n",
    "    # axs[2].set_xlabel('Row index')\n",
    "\n",
    "    # # Savitzky-Golay Filter\n",
    "    # axs[5].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "    # axs[5].plot(data.index[:1000], data[f'{column}_savgol'][:1000], label='Filtered', color='red')\n",
    "    # axs[5].set_title('Savitzky-Golay Filter')\n",
    "    # axs[5].set_xlabel('Row index')\n",
    "    \n",
    "    # # Wavelet Denoising\n",
    "    # axs[6].plot(data.index[:1000], data[column][:1000], label='Original', alpha=0.5)\n",
    "    # axs[6].plot(data.index[:1000], data[f'{column}_wavelet'][:1000], label='Filtered', color='red')\n",
    "    # axs[6].set_title('Wavelet Denoising')\n",
    "    # axs[6].set_xlabel('Row index')\n",
    "    \n",
    "    # for ax in axs:\n",
    "    #     ax.legend()\n",
    "    \n",
    "    # plt.tight_layout()\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in columns_to_process:\n",
    "#     plot_comparison(new_data, column, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data loss\n",
    "for column, losses in data_loss.items():\n",
    "    print(f'Data Loss for {column}:')\n",
    "    for method, loss in losses.items():\n",
    "        print(f'  {method}: {loss}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Dictionary to store the best methods\n",
    "best_methods = {}\n",
    "\n",
    "# Evaluate the data loss\n",
    "for column, losses in data_loss.items():\n",
    "    print(f'Data Loss for {column}:')\n",
    "    \n",
    "    # Initialize best values\n",
    "    best_mae = float('inf')\n",
    "    best_mse = float('inf')\n",
    "    best_mae_method = None\n",
    "    best_mse_method = None\n",
    "    \n",
    "    # Print the data loss for each method and find the best one\n",
    "    for method, loss in losses.items():\n",
    "        print(f'  {method}: {loss}')\n",
    "        if 'MAE' in method:\n",
    "            if loss < best_mae:\n",
    "                best_mae = loss\n",
    "                best_mae_method = method\n",
    "        elif 'MSE' in method:\n",
    "            if loss < best_mse:\n",
    "                best_mse = loss\n",
    "                best_mse_method = method\n",
    "\n",
    "    best_methods[column] = {\n",
    "        'Best MAE Method': best_mae_method,\n",
    "        'Best MAE': best_mae,\n",
    "        'Best MSE Method': best_mse_method,\n",
    "        'Best MSE': best_mse\n",
    "    }\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Display the best method for each column\n",
    "print(\"Best Noise Removal Methods:\")\n",
    "for column, best in best_methods.items():\n",
    "    print(f'{column}:')\n",
    "    print(f'  Best MAE Method: {best[\"Best MAE Method\"]} with MAE = {best[\"Best MAE\"]}')\n",
    "    print(f'  Best MSE Method: {best[\"Best MSE Method\"]} with MSE = {best[\"Best MSE\"]}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
